{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## About Dataset\n",
    "\n",
    "Reddit is a discussion website which users can post images and text in a subforum called subreddit which users can discuss about shared contents in comment section. This dataset contains 05/2015 comment submissions from reddit users with 54.504.410 rows and 22 columns.\n",
    "\n",
    "I got my data from kaggle unfornutely this dataset is too big to run on kaggle so I needed to download it.\n",
    "> https://www.kaggle.com/reddit/reddit-comments-may-2015/notebooks\n",
    "\n",
    "If you want a JSON format of this data you can download it from: https://files.pushshift.io/reddit/comments/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Accessing data from sqlite and cleaning it\n",
    "\n",
    "Used this sqlite query to clean the dataset before extracting it to csv because it caused problems while trying to import the data\n",
    "\n",
    "I didn't import authorflaircss_class field because it is not important for our analysis\n",
    "\n",
    "```sqlite\n",
    "create table reddit_2015_05 as\n",
    "select \n",
    "rd.created_utc,\n",
    "rd.ups,\n",
    "rd.subreddit_id,\n",
    "rd.link_id,\n",
    "rd.name,\n",
    "rd.score_hidden,\n",
    "replace(\n",
    "\treplace(\n",
    "\t\treplace(\n",
    "\t\t\t\treplace(\n",
    "\t\t\t\t\treplace(\n",
    "\t\t\t\t\t\treplace(\n",
    "\t\t\t\t\t\t\treplace(rd.author_flair_text,'\\','')\n",
    "\t\t\t\t\t\t,'*','')\n",
    "\t\t\t\t\t,'#','')\n",
    "\t\t\t\t, X'0A', ' ')\n",
    "\t\t,char(13),' ')\n",
    "\t,';','')\n",
    ",'\"','') as author_flair_text,\n",
    "rd.subreddit,\n",
    "rd.id,\n",
    "rd.removal_reason,\n",
    "rd.gilded,\n",
    "rd.downs,\n",
    "rd.archived,\n",
    "rd.author,\n",
    "rd.score,\n",
    "rd.retrieved_on,\n",
    "replace(\n",
    "\treplace(\n",
    "\t\treplace(\n",
    "\t\t\t\treplace(\n",
    "\t\t\t\t\treplace(\n",
    "\t\t\t\t\t\treplace(\n",
    "\t\t\t\t\t\t\treplace(rd.body,'\\','')\n",
    "\t\t\t\t\t\t,'*','')\n",
    "\t\t\t\t\t,'#','')\n",
    "\t\t\t\t, X'0A', ' ')\n",
    "\t\t,char(13),' ')\n",
    "\t,';','')\n",
    ",'\"','') as body,\n",
    "rd.distinguished,\n",
    "rd.edited,\n",
    "rd.controversiality,\n",
    "rd.parent_id\n",
    "from may2015 rd;\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Splitting csv data to make it ready for import\n",
    "\n",
    "I needed to split my csv file so I can import it to PostgreSQL because PostgreSQL copy command doesn't support files bigger than 4GB\n",
    "\n",
    "I used [csvsplitter](https://www.erdconcepts.com/dbtoolbox/csvsplitter/csvsplitter.zip) from [erdconcepts](https://www.erdconcepts.com/dbtoolbox.html)\n",
    "\n",
    "Opened up cmd and inserted these lines;\n",
    "\n",
    "```cmd\n",
    "cd C:\\data\\reddit\\csvsplitter\n",
    "\n",
    "CSVSplitter.exe filename=\"C:\\data\\reddit\\reddit_2015_05.csv\" rowcount=5000000\n",
    "```\n",
    "\n",
    "It spliced my csv to 11 files ranging from 1.2GB to 1.5GB"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Creating table in PostgreSQL to import our dataset\n",
    "\n",
    "I created my PostgreSQL table with this query\n",
    "\n",
    "```PostgreSQL\n",
    "CREATE TABLE \"ODS\".\"EXT_REDDIT_COMMENTS\"\n",
    "(\n",
    "    created_utc integer,\n",
    "    ups integer,\n",
    "    subreddit_id text COLLATE pg_catalog.\"default\",\n",
    "    link_id text COLLATE pg_catalog.\"default\",\n",
    "    name text COLLATE pg_catalog.\"default\",\n",
    "    score_hidden text COLLATE pg_catalog.\"default\",\n",
    "    author_flair_text text COLLATE pg_catalog.\"default\",\n",
    "    subreddit text COLLATE pg_catalog.\"default\",\n",
    "    id text COLLATE pg_catalog.\"default\",\n",
    "    removal_reason text COLLATE pg_catalog.\"default\",\n",
    "    gilded integer,\n",
    "    downs integer,\n",
    "    archived text COLLATE pg_catalog.\"default\",\n",
    "    author text COLLATE pg_catalog.\"default\",\n",
    "    score integer,\n",
    "    retrieved_on integer,\n",
    "    body text COLLATE pg_catalog.\"default\",\n",
    "    distinguished text COLLATE pg_catalog.\"default\",\n",
    "    edited text COLLATE pg_catalog.\"default\",\n",
    "    controversiality integer,\n",
    "    parent_id text COLLATE pg_catalog.\"default\"\n",
    ")\n",
    "\n",
    "TABLESPACE pg_default;\n",
    "\n",
    "ALTER TABLE \"ODS\".\"EXT_REDDIT_COMMENTS\"\n",
    "    OWNER to postgres;\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Importing dataset\n",
    "\n",
    "Then used PostgreSQL copy command to import my data;\n",
    "\n",
    "```PostgreSQL\n",
    "SET STATEMENT_TIMEOUT TO 3000000;\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-000.CSV' DELIMITER ';';\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-001.CSV' DELIMITER ';';\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-002.CSV' DELIMITER ';';\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-003.CSV' DELIMITER ';';\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-004.CSV' DELIMITER ';';\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-005.CSV' DELIMITER ';';\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-006.CSV' DELIMITER ';';\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-007.CSV' DELIMITER ';';\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-008.CSV' DELIMITER ';';\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-009.CSV' DELIMITER ';';\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-010.CSV' DELIMITER ';';\n",
    "\n",
    "COMMIT;\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Analyzing our data\n",
    "\n",
    "Original dataset is too big to handle(54.504.410 rows with 33.3GB size) maybe we should check if it is possible to reduce our data while not affecting our analysis\n",
    "\n",
    "```PostgreSQL\n",
    "SELECT \n",
    "COUNT(*)                       \n",
    "FROM \"ODS\".\"EXT_REDDIT_COMMENTS\" ERS\n",
    "WHERE 1=1\n",
    "AND LENGTH(ERS.BODY) > 2;\n",
    "```\n",
    "This query reduces our data to 54.333.604 rows while removing comments like 'OK' which is not meaningful on its own.\n",
    "\n",
    "```PostgreSQL\n",
    "SELECT \n",
    "COUNT(*)                       \n",
    "FROM \"ODS\".\"EXT_REDDIT_COMMENTS\" ERS\n",
    "WHERE 1=1\n",
    "AND LENGTH(ERS.BODY) > 2\n",
    "AND (LOWER(ERS.AUTHOR) LIKE '%\\_bot\\_%'\n",
    "OR LOWER(ERS.AUTHOR) LIKE '%\\-bot\\-%');\n",
    "```\n",
    "This would remove 958 bot comments with comment author names contains \"-bot-\" or \"_bot_\", it is not that a huge decrease.\n",
    "\n",
    "```PostgreSQL\n",
    "SELECT\n",
    "COUNT(*)\n",
    "FROM \"ODS\".\"EXT_REDDIT_COMMENTS\" ERS\n",
    "WHERE 1=1\n",
    "AND LENGTH(ERS.BODY) > 2\n",
    "AND NOT (LOWER(ERS.AUTHOR) LIKE '%\\_bot\\_%'\n",
    "OR LOWER(ERS.AUTHOR) LIKE '%\\-bot\\-%')\n",
    "AND NOT(LOWER(REPLACE(ERS.BODY,'''',''))) LIKE '%im a bot%';\n",
    "```\n",
    "We could also filter comments with \"I'm a bot\" text, this also decreases dataset with 24.918 rows.\n",
    "\n",
    "```PostgreSQL\n",
    "SELECT\n",
    "COUNT(*)\n",
    "FROM \"ODS\".\"EXT_REDDIT_COMMENTS\" ERS\n",
    "WHERE 1=1\n",
    "AND LENGTH(ERS.BODY) > 2\n",
    "AND NOT (LOWER(ERS.AUTHOR) LIKE '%\\_bot\\_%'\n",
    "OR LOWER(ERS.AUTHOR) LIKE '%\\-bot\\-%')\n",
    "AND NOT(LOWER(REPLACE(ERS.BODY,'''','')) LIKE '%im a bot%')\n",
    "AND ERS.BODY <> '[deleted]'; --3138587\n",
    "```\n",
    "This query removes deleted comments which is 3.138.587 rows.\n",
    "\n",
    "```PostgreSQL\n",
    "SELECT\n",
    "COUNT(*)\n",
    "FROM \"ODS\".\"EXT_REDDIT_COMMENTS\" ERS\n",
    "WHERE 1=1\n",
    "AND LENGTH(ERS.BODY) > 2\n",
    "AND NOT (LOWER(ERS.AUTHOR) LIKE '%\\_bot\\_%'\n",
    "OR LOWER(ERS.AUTHOR) LIKE '%\\-bot\\-%')\n",
    "AND NOT(LOWER(REPLACE(ERS.BODY,'''','')) LIKE '%im a bot%')\n",
    "AND ERS.BODY <> '[deleted]'\n",
    "AND LENGTH(ERS.REMOVAL_REASON) = 0;\n",
    "```\n",
    "We should also remove removed comments which is replaced by removal reason instead of original comments.\n",
    "\n",
    "```PostgreSQL\n",
    "SELECT\n",
    "COUNT(*)\n",
    "FROM \"ODS\".\"EXT_REDDIT_COMMENTS\" ERS\n",
    "WHERE 1=1\n",
    "AND LENGTH(ERS.BODY) > 2\n",
    "AND NOT (LOWER(ERS.AUTHOR) LIKE '%\\_bot\\_%'\n",
    "OR LOWER(ERS.AUTHOR) LIKE '%\\-bot\\-%')\n",
    "AND NOT(LOWER(REPLACE(ERS.BODY,'''','')) LIKE '%im a bot%')\n",
    "AND ERS.BODY <> '[deleted]'\n",
    "AND LENGTH(ERS.removal_reason) = 0\n",
    "AND ERS.BODY LIKE '% %';\n",
    "```\n",
    "We should remove single word comments(1.885.966 rows) because they are not important for our analysis.\n",
    "\n",
    "```PostgreSQL\n",
    "SELECT\n",
    "COUNT(*)\n",
    "FROM \"ODS\".\"EXT_REDDIT_COMMENTS\" ERS\n",
    "WHERE 1=1\n",
    "AND LENGTH(ERS.BODY) > 2\n",
    "AND NOT (LOWER(ERS.AUTHOR) LIKE '%\\_bot\\_%'\n",
    "OR LOWER(ERS.AUTHOR) LIKE '%\\-bot\\-%')\n",
    "AND NOT(LOWER(REPLACE(ERS.BODY,'''','')) LIKE '%im a bot%')\n",
    "AND ERS.BODY <> '[deleted]'\n",
    "AND LENGTH(ERS.removal_reason) = 0\n",
    "AND ERS.BODY LIKE '% %'\n",
    "AND ERS.AUTHOR <> 'AutoModerator';\n",
    "```\n",
    "With this query we remove \"AutoModerator\" user which every subreddit uses it for moderation purposes, It filters 286.444 rows.\n",
    "\n",
    "```PostgreSQL\n",
    "SELECT\n",
    "COUNT(*)\n",
    "FROM \"ODS\".\"EXT_REDDIT_COMMENTS\" ERS\n",
    "WHERE 1=1\n",
    "AND LENGTH(ERS.BODY) > 2\n",
    "AND NOT(LOWER(ERS.AUTHOR) LIKE '%\\_bot\\_%' OR LOWER(ERS.AUTHOR) LIKE '%\\-bot\\-%')\n",
    "AND NOT(LOWER(REPLACE(ERS.BODY,'''','')) LIKE '%im a bot%')\n",
    "AND ERS.BODY <> '[deleted]'\n",
    "AND LENGTH(ERS.removal_reason) = 0\n",
    "AND ERS.BODY LIKE '% %'\n",
    "AND ERS.AUTHOR <> 'AutoModerator'\n",
    "AND ERS.AUTHOR <> '[deleted]'\n",
    "```\n",
    "Filtering deleted authors removes 305.983 rows."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Table already exists\nIndex already exists\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "import time\n",
    "import math\n",
    "\n",
    "conn_string = 'host={pghost} port={pgport} dbname={pgdatabase} user={pguser} password={pgpassword}'.format(pgdatabase='MEF-BDA-PROD',pguser='postgres',pgpassword='123',pghost='localhost',pgport='5432')\n",
    "conn=psycopg2.connect(conn_string)\n",
    "cur=conn.cursor()\n",
    "\n",
    "def check_if_table_exists(schema,table):\n",
    "    cur.execute(\"select exists(select * from information_schema.tables where table_schema='{schema}' AND table_name='{table}')\".format(schema=schema, table=table))\n",
    "    return cur.fetchone()[0]\n",
    "\n",
    "def check_if_index_exists(index):\n",
    "    cur.execute(\"SELECT EXISTS(SELECT * FROM PG_CLASS WHERE relname = '{index}')\".format(index=index))\n",
    "    return cur.fetchone()[0]\n",
    "\n",
    "if(check_if_table_exists('EDW','DWH_REDDIT_COMMENTS')):\n",
    "    print('Table already exists')   \n",
    "else:\n",
    "    start_time = time.time()\n",
    "    cur.execute('set time zone UTC;')\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"EDW\".\"DWH_REDDIT_COMMENTS\" AS \n",
    "    SELECT\n",
    "    ROW_NUMBER() OVER (ORDER BY ERS.ID) AS ID,\n",
    "    TO_TIMESTAMP(GREATEST(ERS.CREATED_UTC ,CAST(ERS.EDITED AS INTEGER))) AS DATE,\n",
    "    ERS.SUBREDDIT,\n",
    "    ERS.AUTHOR,\n",
    "    ERS.AUTHOR_FLAIR_TEXT,\n",
    "    ERS.SCORE,\n",
    "    ERS.BODY AS COMMENT\n",
    "    FROM \"ODS\".\"EXT_REDDIT_COMMENTS\" ERS\n",
    "    WHERE 1=1\n",
    "    AND LENGTH(ERS.BODY) > 2\n",
    "    AND NOT(LOWER(ERS.AUTHOR) LIKE '%\\_bot\\_%' OR LOWER(ERS.AUTHOR) LIKE '%\\-bot\\-%')\n",
    "    AND NOT(LOWER(REPLACE(ERS.BODY,'''','')) LIKE '%im a bot%')\n",
    "    AND ERS.BODY <> '[deleted]'\n",
    "    AND LENGTH(ERS.removal_reason) = 0\n",
    "    AND ERS.BODY LIKE '% %'\n",
    "    AND ERS.AUTHOR <> 'AutoModerator'\n",
    "    AND ERS.AUTHOR <> '[deleted]';\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    print(\"Table created in {execute_time} seconds\".format(execute_time=math.trunc(time.time()-start_time)))\n",
    "\n",
    "if(check_if_index_exists('IDX_DWH_REDDIT_COMMENTS#01')):\n",
    "    print('Index already exists')\n",
    "else:\n",
    "    start_time = time.time()\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE INDEX \"IDX_DWH_REDDIT_COMMENTS#01\" \n",
    "    ON \"EDW\".\"DWH_REDDIT_COMMENTS\" USING BTREE(\n",
    "        \"id\" ASC NULLS LAST,\n",
    "        \"date\" ASC NULLS LAST\n",
    "    )\n",
    "    TABLESPACE PG_DEFAULT;\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    print(\"Index created in {execute_time} seconds\".format(execute_time=math.trunc(time.time()-start_time)))"
   ]
  },
  {
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords', quiet=True)\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "sql_command = 'SELECT * FROM \"{schema}\".\"{table}\" WHERE ID = 15;'.format(schema='EDW', table='DWH_REDDIT_COMMENTS')\n",
    "df = pd.read_sql(sql_command,conn)\n",
    "print(\"Original comment:\\n{comment}\\n\\n\".format(comment=df['comment'][0]))\n",
    "\n",
    "df['comment'] = df['comment'].apply(lambda x: ' '.join([word for word in x.lower().split() if word not in (stop)]))\n",
    "\n",
    "print(\"Comment after removing stopwords:\\n{comment}\\n\\n\".format(comment=df['comment'][0]))\n",
    "\n",
    "start_time = time.time()\n",
    "cur.execute(\"\"\"\n",
    "UPDATE \"EDW\".\"DWH_REDDIT_COMMENTS\"\n",
    "SET \"comment\" = %(comment)s\n",
    "WHERE \"id\" = %(id)s\n",
    "\"\"\", {'comment': str(df['comment'][0]), 'id': int(df['id'][0])})\n",
    "\n",
    "print(\"Updated record(s) in {execute_time} seconds\\n\".format(execute_time=math.trunc(time.time()-start_time)))\n",
    "\n",
    "sql_command = 'SELECT * FROM \"{schema}\".\"{table}\" WHERE ID = 15;'.format(schema='EDW', table='DWH_REDDIT_COMMENTS')\n",
    "df = pd.read_sql(sql_command,conn)\n",
    "print(\"Comment in table:\\n{comment}\\n\\n\".format(comment=df['comment'][0]))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Original comment:\nIt's not your fault don't think that. Hey if this helps it does then if it doesn't well. At least I can talk about it.  I shot my dog. I had him for 10 years. I can home from partying and it was New Years so I was going to shoot off my .40 so...  Well I was loading it outside and I shot it off accidentally. Right into my dog. Me having about 5-7 tequila shots into me though if I go to sleep I would wake up and he would be okay. Well if I called a vet when I shot him I could have saved him. Or at least from his pain. So I woke up saw a dead dog in my yard… i cried for hours. That old dog still had a few good years in him.   That was my fault and you sitting on a little tiny mouse is more understandable than a man discharging a firearm into a shitzu. Don't feel to bad. \n\n\nComment after removing stopwords:\nfault think that. hey helps well. least talk it. shot dog. 10 years. home partying new years going shoot .40 so... well loading outside shot accidentally. right dog. 5-7 tequila shots though go sleep would wake would okay. well called vet shot could saved him. least pain. woke saw dead dog yard… cried hours. old dog still good years him. fault sitting little tiny mouse understandable man discharging firearm shitzu. feel bad.\n\n\nUpdated record(s) in 0 seconds\n\nComment in table:\nfault think that. hey helps well. least talk it. shot dog. 10 years. home partying new years going shoot .40 so... well loading outside shot accidentally. right dog. 5-7 tequila shots though go sleep would wake would okay. well called vet shot could saved him. least pain. woke saw dead dog yard… cried hours. old dog still good years him. fault sitting little tiny mouse understandable man discharging firearm shitzu. feel bad.\n\n\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "source": [
    "## Sources:\n",
    "\n",
    " 1. [About Reddit](https://en.wikipedia.org/wiki/Reddit)\n",
    "\n",
    " 2. [Data source](https://www.kaggle.com/reddit/reddit-comments-may-2015/notebooks)\n",
    "\n",
    " 3. [Checking if a table exist with psycopg2 on postgreSQL](https://stackoverflow.com/questions/1874113/checking-if-a-postgresql-table-exists-under-python-and-probably-psycopg2)\n",
    "\n",
    " 4. [Using current time in UTC as default value in PostgreSQL. This is important because date is utc in the data](https://stackoverflow.com/questions/16609724/using-current-time-in-utc-as-default-value-in-postgresql)\n",
    "\n",
    " 5. [Creating multicolumn index on PostgreSQL](https://www.postgresql.org/docs/9.6/indexes-multicolumn.html)\n",
    "\n",
    " 6. [Checking if index exist](https://stackoverflow.com/questions/45983169/checking-for-existence-of-index-in-postgresql)\n",
    "\n",
    " 7. [How to execute start time and end time in python](https://www.codegrepper.com/code-examples/delphi/how+to+execute+from+start+time+to+end+time+in+python)\n",
    "\n",
    " 8. [Truncating numbers in python](https://www.w3schools.com/python/ref_math_trunc.asp)\n",
    "\n",
    " 9. [Removing stopwords](https://stackoverflow.com/questions/29523254/python-remove-stop-words-from-pandas-dataframe)\n",
    "\n",
    " 10. [Prevent SQL Injection in Python](https://realpython.com/prevent-python-sql-injection/)\n",
    "\n",
    " 11. [Preventing SQL Injection resulted errors but It needed to be done, data type conversation is the key here](https://stackoverflow.com/questions/39564755/programmingerror-psycopg2-programmingerror-cant-adapt-type-numpy-ndarray)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}