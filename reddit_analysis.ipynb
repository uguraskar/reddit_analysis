{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## About Dataset\n",
    "\n",
    "Reddit is a discussion website which users can post images and text in a subforum called subreddit which users can discuss about shared contents in comment section. This dataset contains 05/2015 comment submissions from reddit users with 54.504.410 rows and 22 columns.\n",
    "\n",
    "I got my data from kaggle unfornutely this dataset is too big to run on kaggle so I needed to download it.\n",
    "> https://www.kaggle.com/reddit/reddit-comments-may-2015/notebooks\n",
    "\n",
    "If you want a JSON format of this data you can download it from: https://files.pushshift.io/reddit/comments/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Accessing data from sqlite and cleaning it\n",
    "\n",
    "Used this sqlite query to clean the dataset before extracting it to csv because it caused problems while trying to import the data\n",
    "\n",
    "I didn't import authorflaircss_class field because it is not important for our analysis\n",
    "\n",
    "```sqlite\n",
    "create table reddit_2015_05 as\n",
    "select \n",
    "rd.created_utc,\n",
    "rd.ups,\n",
    "rd.subreddit_id,\n",
    "rd.link_id,\n",
    "rd.name,\n",
    "rd.score_hidden,\n",
    "replace(\n",
    "\treplace(\n",
    "\t\treplace(\n",
    "\t\t\t\treplace(\n",
    "\t\t\t\t\treplace(\n",
    "\t\t\t\t\t\treplace(\n",
    "\t\t\t\t\t\t\treplace(rd.author_flair_text,'\\','')\n",
    "\t\t\t\t\t\t,'*','')\n",
    "\t\t\t\t\t,'#','')\n",
    "\t\t\t\t, X'0A', ' ')\n",
    "\t\t,char(13),' ')\n",
    "\t,';','')\n",
    ",'\"','') as author_flair_text,\n",
    "rd.subreddit,\n",
    "rd.id,\n",
    "rd.removal_reason,\n",
    "rd.gilded,\n",
    "rd.downs,\n",
    "rd.archived,\n",
    "rd.author,\n",
    "rd.score,\n",
    "rd.retrieved_on,\n",
    "replace(\n",
    "\treplace(\n",
    "\t\treplace(\n",
    "\t\t\t\treplace(\n",
    "\t\t\t\t\treplace(\n",
    "\t\t\t\t\t\treplace(\n",
    "\t\t\t\t\t\t\treplace(rd.body,'\\','')\n",
    "\t\t\t\t\t\t,'*','')\n",
    "\t\t\t\t\t,'#','')\n",
    "\t\t\t\t, X'0A', ' ')\n",
    "\t\t,char(13),' ')\n",
    "\t,';','')\n",
    ",'\"','') as body,\n",
    "rd.distinguished,\n",
    "rd.edited,\n",
    "rd.controversiality,\n",
    "rd.parent_id\n",
    "from may2015 rd;\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Splitting csv data to make it ready for import\n",
    "\n",
    "I needed to split my csv file so I can import it to PostgreSQL because PostgreSQL copy command doesn't support files bigger than 4GB\n",
    "\n",
    "I used [csvsplitter](https://www.erdconcepts.com/dbtoolbox/csvsplitter/csvsplitter.zip) from [erdconcepts](https://www.erdconcepts.com/dbtoolbox.html)\n",
    "\n",
    "Opened up cmd and inserted these lines;\n",
    "\n",
    "```cmd\n",
    "cd C:\\data\\reddit\\csvsplitter\n",
    "\n",
    "CSVSplitter.exe filename=\"C:\\data\\reddit\\reddit_2015_05.csv\" rowcount=5000000\n",
    "```\n",
    "\n",
    "It spliced my csv to 11 files ranging from 1.2GB to 1.5GB"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Creating table in PostgreSQL to import our dataset\n",
    "\n",
    "I created my PostgreSQL table with this query\n",
    "\n",
    "```PostgreSQL\n",
    "CREATE TABLE \"ODS\".\"EXT_REDDIT_COMMENTS\"\n",
    "(\n",
    "    created_utc integer,\n",
    "    ups integer,\n",
    "    subreddit_id text COLLATE pg_catalog.\"default\",\n",
    "    link_id text COLLATE pg_catalog.\"default\",\n",
    "    name text COLLATE pg_catalog.\"default\",\n",
    "    score_hidden text COLLATE pg_catalog.\"default\",\n",
    "    author_flair_text text COLLATE pg_catalog.\"default\",\n",
    "    subreddit text COLLATE pg_catalog.\"default\",\n",
    "    id text COLLATE pg_catalog.\"default\",\n",
    "    removal_reason text COLLATE pg_catalog.\"default\",\n",
    "    gilded integer,\n",
    "    downs integer,\n",
    "    archived text COLLATE pg_catalog.\"default\",\n",
    "    author text COLLATE pg_catalog.\"default\",\n",
    "    score integer,\n",
    "    retrieved_on integer,\n",
    "    body text COLLATE pg_catalog.\"default\",\n",
    "    distinguished text COLLATE pg_catalog.\"default\",\n",
    "    edited text COLLATE pg_catalog.\"default\",\n",
    "    controversiality integer,\n",
    "    parent_id text COLLATE pg_catalog.\"default\"\n",
    ")\n",
    "\n",
    "TABLESPACE pg_default;\n",
    "\n",
    "ALTER TABLE \"ODS\".\"EXT_REDDIT_COMMENTS\"\n",
    "    OWNER to postgres;\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Importing dataset\n",
    "\n",
    "Then used PostgreSQL copy command to import my data;\n",
    "\n",
    "```PostgreSQL\n",
    "SET STATEMENT_TIMEOUT TO 3000000;\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-000.CSV' DELIMITER ';';\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-001.CSV' DELIMITER ';';\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-002.CSV' DELIMITER ';';\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-003.CSV' DELIMITER ';';\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-004.CSV' DELIMITER ';';\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-005.CSV' DELIMITER ';';\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-006.CSV' DELIMITER ';';\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-007.CSV' DELIMITER ';';\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-008.CSV' DELIMITER ';';\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-009.CSV' DELIMITER ';';\n",
    "\n",
    "COPY \"ODS\".\"EXT_REDDIT_COMMENTS\" FROM 'C:/data/reddit/REDDIT_2015_05-010.CSV' DELIMITER ';';\n",
    "\n",
    "COMMIT;\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Analyzing our data\n",
    "\n",
    "Original dataset is too big to handle(54.504.410 rows with 33.3GB size) maybe we should check if it is possible to reduce our data while not affecting our analysis\n",
    "\n",
    "```PostgreSQL\n",
    "SELECT \n",
    "COUNT(*)                       \n",
    "FROM \"ODS\".\"EXT_REDDIT_COMMENTS\" ERS\n",
    "WHERE 1=1\n",
    "AND LENGTH(ERS.BODY) > 2;\n",
    "```\n",
    "This query reduces our data to 54.333.604 rows while removing comments like 'OK'\n",
    "\n",
    "```PostgreSQL\n",
    "SELECT \n",
    "COUNT(*)                       \n",
    "FROM \"ODS\".\"EXT_REDDIT_COMMENTS\" ERS\n",
    "WHERE 1=1\n",
    "AND LENGTH(ERS.BODY) > 2\n",
    "AND (LOWER(ERS.AUTHOR) LIKE '%\\_bot\\_%'\n",
    "OR LOWER(ERS.AUTHOR) LIKE '%\\-bot\\-%');\n",
    "```\n",
    "This would remove 958 bot comments with comment author names contains \"-bot-\" or \"_bot_\" so it is not that huge decrease\n",
    "\n",
    "```PostgreSQL\n",
    "SELECT\n",
    "COUNT(*)\n",
    "FROM \"ODS\".\"EXT_REDDIT_COMMENTS\" ERS\n",
    "WHERE 1=1\n",
    "AND LENGTH(ERS.BODY) > 2\n",
    "AND NOT (LOWER(ERS.AUTHOR) LIKE '%\\_bot\\_%'\n",
    "OR LOWER(ERS.AUTHOR) LIKE '%\\-bot\\-%')\n",
    "AND NOT(LOWER(REPLACE(ERS.BODY,'''',''))) LIKE '%im a bot%';\n",
    "```\n",
    "We could also filter comments with \"I'm a bot\" text, this also decreases dataset with 24.918 rows\n",
    "\n",
    "```PostgreSQL\n",
    "SELECT\n",
    "COUNT(*)\n",
    "FROM \"ODS\".\"EXT_REDDIT_COMMENTS\" ERS\n",
    "WHERE 1=1\n",
    "AND LENGTH(ERS.BODY) > 2\n",
    "AND NOT (LOWER(ERS.AUTHOR) LIKE '%\\_bot\\_%'\n",
    "OR LOWER(ERS.AUTHOR) LIKE '%\\-bot\\-%')\n",
    "AND NOT(LOWER(REPLACE(ERS.BODY,'''','')) LIKE '%im a bot%')\n",
    "AND ERS.BODY <> '[deleted]'; --3138587\n",
    "```\n",
    "This query removes deleted comments which is 3.138.587 rows\n",
    "\n",
    "```PostgreSQL\n",
    "SELECT\n",
    "COUNT(*)\n",
    "FROM \"ODS\".\"EXT_REDDIT_COMMENTS\" ERS\n",
    "WHERE 1=1\n",
    "AND LENGTH(ERS.BODY) > 2\n",
    "AND NOT (LOWER(ERS.AUTHOR) LIKE '%\\_bot\\_%'\n",
    "OR LOWER(ERS.AUTHOR) LIKE '%\\-bot\\-%')\n",
    "AND NOT(LOWER(REPLACE(ERS.BODY,'''','')) LIKE '%im a bot%')\n",
    "AND ERS.BODY <> '[deleted]'\n",
    "AND LENGTH(ERS.REMOVAL_REASON) = 0;\n",
    "```\n",
    "We should also remove removed comments which is replaced by removal reason instead of original comments.\n",
    "\n",
    "```PostgreSQL\n",
    "SELECT\n",
    "COUNT(*)\n",
    "FROM \"ODS\".\"EXT_REDDIT_COMMENTS\" ERS\n",
    "WHERE 1=1\n",
    "AND LENGTH(ERS.BODY) > 2\n",
    "AND NOT (LOWER(ERS.AUTHOR) LIKE '%\\_bot\\_%'\n",
    "OR LOWER(ERS.AUTHOR) LIKE '%\\-bot\\-%')\n",
    "AND NOT(LOWER(REPLACE(ERS.BODY,'''','')) LIKE '%im a bot%')\n",
    "AND ERS.BODY <> '[deleted]'\n",
    "AND LENGTH(ERS.removal_reason) = 0\n",
    "AND ERS.BODY LIKE '% %';\n",
    "```\n",
    "We should remove single word comments(1.885.966 rows) because they are not important for our analysis.\n",
    "\n",
    "```PostgreSQL\n",
    "SELECT\n",
    "COUNT(*)\n",
    "FROM \"ODS\".\"EXT_REDDIT_COMMENTS\" ERS\n",
    "WHERE 1=1\n",
    "AND LENGTH(ERS.BODY) > 2\n",
    "AND NOT (LOWER(ERS.AUTHOR) LIKE '%\\_bot\\_%'\n",
    "OR LOWER(ERS.AUTHOR) LIKE '%\\-bot\\-%')\n",
    "AND NOT(LOWER(REPLACE(ERS.BODY,'''','')) LIKE '%im a bot%')\n",
    "AND ERS.BODY <> '[deleted]'\n",
    "AND LENGTH(ERS.removal_reason) = 0\n",
    "AND ERS.BODY LIKE '% %'\n",
    "AND ERS.AUTHOR <> 'AutoModerator';\n",
    "```\n",
    "286.444\n",
    "\n",
    "```PostgreSQL\n",
    "SELECT\n",
    "COUNT(*)\n",
    "FROM \"ODS\".\"EXT_REDDIT_COMMENTS\" ERS\n",
    "WHERE 1=1\n",
    "AND LENGTH(ERS.BODY) > 2\n",
    "AND NOT(LOWER(ERS.AUTHOR) LIKE '%\\_bot\\_%' OR LOWER(ERS.AUTHOR) LIKE '%\\-bot\\-%')\n",
    "AND NOT(LOWER(REPLACE(ERS.BODY,'''','')) LIKE '%im a bot%')\n",
    "AND ERS.BODY <> '[deleted]'\n",
    "AND LENGTH(ERS.removal_reason) = 0\n",
    "AND ERS.BODY LIKE '% %'\n",
    "AND ERS.AUTHOR <> 'AutoModerator'\n",
    "AND ERS.AUTHOR <> '[deleted]'\n",
    "```\n",
    "305.983"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Table created\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "\n",
    "conn_string = 'host={pghost} port={pgport} dbname={pgdatabase} user={pguser} password={pgpassword}'.format(pgdatabase='MEF-BDA-PROD',pguser='postgres',pgpassword='123',pghost='localhost',pgport='5432')\n",
    "conn=psycopg2.connect(conn_string)\n",
    "cur=conn.cursor()\n",
    "\n",
    "def check_if_table_exists(schema,table):\n",
    "    cur.execute(\"select exists(select * from information_schema.tables where table_schema='{schema}' AND table_name='{table}')\".format(schema=schema, table=table))\n",
    "    return cur.fetchone()[0]\n",
    "\n",
    "def(check_if_index_exist)(index):\n",
    "    cur.execute(\"SELECT EXISTS(SELECT * FROM PG_CLASS WHERE relname = {index})\".format(index=index))\n",
    "    return cur.fetchone()[0]\n",
    "\n",
    "if(check_if_table_exists('EDW','DWH_REDDIT_COMMENTS')):\n",
    "    print('Table already exists')   \n",
    "else:\n",
    "    cur.execute('set time zone UTC;')\n",
    "    cur.execute(\"\"\"\n",
    "    CREATE TABLE \"EDW\".\"DWH_REDDIT_COMMENTS\" AS \n",
    "    SELECT\n",
    "    ROW_NUMBER() OVER (ORDER BY ERS.ID) AS ID,\n",
    "    TO_TIMESTAMP(GREATEST(ERS.CREATED_UTC ,CAST(ERS.EDITED AS INTEGER))) AS DATE,\n",
    "    ERS.SUBREDDIT,\n",
    "    ERS.AUTHOR,\n",
    "    ERS.AUTHOR_FLAIR_TEXT,\n",
    "    ERS.SCORE,\n",
    "    ERS.BODY AS COMMENT\n",
    "    FROM \"ODS\".\"EXT_REDDIT_COMMENTS\" ERS\n",
    "    WHERE 1=1\n",
    "    AND LENGTH(ERS.BODY) > 2\n",
    "    AND NOT(LOWER(ERS.AUTHOR) LIKE '%\\_bot\\_%' OR LOWER(ERS.AUTHOR) LIKE '%\\-bot\\-%')\n",
    "    AND NOT(LOWER(REPLACE(ERS.BODY,'''','')) LIKE '%im a bot%')\n",
    "    AND ERS.BODY <> '[deleted]'\n",
    "    AND LENGTH(ERS.removal_reason) = 0\n",
    "    AND ERS.BODY LIKE '% %'\n",
    "    AND ERS.AUTHOR <> 'AutoModerator'\n",
    "    AND ERS.AUTHOR <> '[deleted]';\n",
    "    \"\"\")\n",
    "    cur.execute('COMMIT;')\n",
    "    print('Table created')\n",
    "\n",
    "#sql_command = 'SELECT * FROM \"{schema}\".\"{table}\";'.format(schema='EDW', table='DWH_REDDIT_COMMENTS')\n",
    "\n",
    "#df = pd.read_sql(sql_command,conn)\n",
    "\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "#print(df.memory_usage(index=True).sum())\n",
    "\n",
    "#df"
   ]
  },
  {
   "source": [
    "## Sources:\n",
    "\n",
    " 1. [About Reddit](https://en.wikipedia.org/wiki/Reddit)\n",
    "\n",
    " 2. [Data source](https://www.kaggle.com/reddit/reddit-comments-may-2015/notebooks)\n",
    "\n",
    " 3. [Checking if a table exist with psycopg2 on postgreSQL](https://stackoverflow.com/questions/1874113/checking-if-a-postgresql-table-exists-under-python-and-probably-psycopg2)\n",
    "\n",
    " 4. [Using current time in UTC as default value in PostgreSQL](https://stackoverflow.com/questions/16609724/using-current-time-in-utc-as-default-value-in-postgresql)\n",
    "\n",
    " 5. [Creating multicolumn index on PostgreSQL](https://www.postgresql.org/docs/9.6/indexes-multicolumn.html)\n",
    "\n",
    " 6. [Checking if index exist](https://stackoverflow.com/questions/45983169/checking-for-existence-of-index-in-postgresql)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}